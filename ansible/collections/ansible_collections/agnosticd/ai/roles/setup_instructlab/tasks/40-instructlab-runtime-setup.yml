---
- name: Venv and iLab Python setup
  block:

    - name: Setup a Python 3.11 virtual environment
      ansible.builtin.command:
        cmd: "python3.11 -m venv /home/{{ setup_instructlab_user }}/instructlab/venv"
      args:
        creates: "/home/{{ setup_instructlab_user }}/instructlab/venv"

    - name: Install InstructLab package from local git repo
      when: r_git_clone_instructlab.changed
      ansible.builtin.command:
        cmd: >-
          /home/{{ setup_instructlab_user }}/instructlab/venv/bin/pip
          install {{ setup_instructlab_home }}
    
    # TODO: Remove or deactivate this hack when no longer needed

    - name: Replace tokenizer.eos_token with tokenizer.unk_token in linux_train.py
      ansible.builtin.replace:
        path: >-
          {{ setup_instructlab_home }}/venv/lib/python{{ setup_instructlab_python_version }}/site-packages/instructlab/train/linux_train.py
        regexp: 'tokenizer\.eos_token'
        replace: 'tokenizer.unk_token'

    - name: Install InstructLab package from local git repo again after change - rebuild wheel
      when: r_git_clone_instructlab.changed
      ansible.builtin.command:
        cmd: >-
          /home/{{ setup_instructlab_user }}/instructlab/venv/bin/pip
          install {{ setup_instructlab_home }}

    - name: Setup llama-cpp-python with CUDA Support
      ansible.builtin.command:
        cmd: >-
            {{ setup_instructlab_home }}/venv/bin/pip install --force-reinstall 
            --no-cache-dir "llama-cpp-python[server]=={{ setup_instructlab_llama_cpp_python_version }}
      environment:
        CUDACXX: /usr/local/cuda-12/bin/nvcc 
        CMAKE_ARGS: "-DLLAMA_CUBLAS=on -DCMAKE_CUDA_ARCHITECTURES=all-major" 
        FORCE_CMAKE: 1 

  become_user: "{{ setup_instructlab_user }}"
